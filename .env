# Choose one LLM provider: openai | ollama
LLM_PROVIDER=ollama
# OPENAI_API_KEY=sk-...
# OPENAI_MODEL=gpt-4o-mini
# For Ollama (local): set a chat model you've pulled (e.g. llama3.1:8b-instruct or mistral)
OLLAMA_MODEL=gemma3:4b

# Paths
DATA_DIR=./data/docs
CHROMA_DIR=./data/chroma
BM25_PATH=./data/bm25_corpus.json

# Retrieval
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
TOP_K=8
HYBRID_ALPHA=0.5  # 0=BM25 only, 1=Vectors only

# Safety
ENABLE_GUARDRAILS=false
MASKING_STRATEGY=brackets  # brackets | stars

ANONYMIZED_TELEMETRY=false

